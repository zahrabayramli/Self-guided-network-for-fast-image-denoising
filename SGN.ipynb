{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahrabayramli/Self-guided-network-for-fast-image-denoising/blob/master/SGN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-wlpm5f92si",
        "outputId": "46aa589c-6b1d-4dba-9c96-891100163f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmk9YKgp-jPK"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import time\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.io\n",
        "import torchvision.transforms.functional as F2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyq-Oija-mOg"
      },
      "outputs": [],
      "source": [
        "class SubNetwork(nn.Module):\n",
        "    def __init__(self, g, m, c_in, c_k, c_out, sub_network_type):\n",
        "        super(SubNetwork, self).__init__()\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(c_in, c_k, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "        if sub_network_type != 'TOP':\n",
        "          self.conv2 = nn.Conv2d(c_k // 2 * 3, c_k, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        if sub_network_type != 'BOTTOM':\n",
        "          self.res_block = nn.ModuleList()\n",
        "          for i in range(g-1):\n",
        "            self.res_block.append(nn.Conv2d(c_k, c_k, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "            self.res_block.append(self.act)\n",
        "          self.res_block.append(nn.Conv2d(c_k, c_k, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "          \n",
        "          self.conv_last = nn.ModuleList([nn.Conv2d(c_k, c_k, kernel_size=3, stride=1, padding=1, bias=False)])\n",
        "          self.conv_last.append(self.act)\n",
        "          \n",
        "        else:\n",
        "          self.res_block = None\n",
        "          self.conv_last = nn.ModuleList()\n",
        "          for i in range(m):\n",
        "            self.conv_last.append(nn.Conv2d(c_k, c_k, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "            self.conv_last.append(self.act)\n",
        "\n",
        "          self.conv_last.append(nn.Conv2d(c_k, c_out, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "\n",
        "    def forward(self, x, upper_features=None):\n",
        "      x = self.act(self.conv1(x))\n",
        "\n",
        "      if upper_features != None:\n",
        "        x = torch.concat((x, F.pixel_shuffle(upper_features, 2)), 1)\n",
        "        x = self.act(self.conv2(x))\n",
        "\n",
        "      if self.res_block != None:\n",
        "        y = x\n",
        "        for l in self.res_block:\n",
        "          y = l(y)\n",
        "        x = self.act(torch.add(x, y))\n",
        "\n",
        "      for l in self.conv_last:\n",
        "        x = l(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "class SGN(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(SGN, self).__init__()\n",
        "        \n",
        "        c_in = args.in_channels\n",
        "        c_0 = args.start_channels\n",
        "        c_out = args.out_channels\n",
        "        m = args.m_block\n",
        "        g = args.g\n",
        "        self.K = args.K\n",
        "\n",
        "        self.bottom = SubNetwork(g, m, c_in, c_0, c_out, 'BOTTOM')\n",
        "\n",
        "        c_k = c_0\n",
        "        self.middle = nn.ModuleList()\n",
        "        for i in range(self.K):\n",
        "          c_k *= 2\n",
        "          c_in *= 4\n",
        "          self.middle.append(SubNetwork(g, m, c_in, c_k, c_out, 'MIDDLE'))\n",
        "\n",
        "        c_k *= 2\n",
        "        c_in *= 4\n",
        "        self.top = SubNetwork(g, m, c_in, c_k, c_out, 'TOP')\n",
        "\n",
        "    def forward(self, x):\n",
        "      l = [x]\n",
        "      for i in range(self.K + 1):\n",
        "        l.append(F.pixel_unshuffle(l[-1], 2))\n",
        "      \n",
        "      upper_features = self.top(l[-1])\n",
        "      i = -2\n",
        "      for middle in reversed(self.middle):\n",
        "        upper_features = middle(l[i], upper_features)\n",
        "        i -= 1\n",
        "      \n",
        "      x = self.bottom(x, upper_features)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wog-Q_7UjF-S"
      },
      "outputs": [],
      "source": [
        "# Configurations & Hyper-parameters\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "# set manual seeds \n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "\n",
        "args = edict()\n",
        "\n",
        "# basic options\n",
        "args.root = '/gdrive/My Drive/CS492I/project' \n",
        "args.name = 'main'                   # experiment name.\n",
        "args.ckpt_dir = 'ckpts'              # checkpoint directory name.\n",
        "args.ckpt_iter = 1000                # how frequently checkpoints are saved.\n",
        "args.ckpt_reload = 'best'            # which checkpoint to re-load.\n",
        "args.gpu = True                      # whether or not to use gpu. \n",
        "\n",
        "# network options\n",
        "args.in_channels = 3\n",
        "args.out_channels = 3\n",
        "args.start_channels = 32\n",
        "args.m_block = 2\n",
        "args.g = 3\n",
        "args.K = 2\n",
        "\n",
        "# data options\n",
        "args.train_data_root = '/DIV2K_train_HR'\n",
        "args.test_data_root = '/DIV2K_valid_HR'\n",
        "args.crop_size = 256\n",
        "args.mu = 0.0\n",
        "args.sigma = 30.0\n",
        "\n",
        "# training options\n",
        "args.epoch = 100                     # training epoch.\n",
        "args.batch_size = 8                  # number of mini-batch size.\n",
        "args.lr = 0.0001                     # learning rate.\n",
        "args.betas = (0.9, 0.999)\n",
        "args.weight_decay = 0\n",
        "\n",
        "# tensorboard options\n",
        "args.tensorboard = True              # whether or not to use tensorboard logging.\n",
        "args.log_dir = 'logs'                # to which tensorboard logs will be saved.\n",
        "args.log_iter = 10                   # how frequently logs are saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7OTfBZnmOUu"
      },
      "outputs": [],
      "source": [
        "# Basic settings\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "result_dir = Path(args.root) / 'results'\n",
        "result_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "global_step = 0\n",
        "best_psnr = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73xfPF2kmVon"
      },
      "outputs": [],
      "source": [
        "# Define train/test data loaders  \n",
        "# Use data augmentation in training set to mitigate overfitting.\n",
        "\n",
        "class DatasetClass(Dataset):\n",
        "    def __init__(self, is_train=True):\n",
        "        self.is_train = is_train\n",
        "        if is_train:\n",
        "            path = args.root + args.train_data_root\n",
        "            self.cropper = transforms.RandomCrop(args.crop_size)\n",
        "            self.flipper = transforms.RandomHorizontalFlip(0.5)\n",
        "        else:\n",
        "            path = args.root + args.test_data_root\n",
        "            self.resizer = transforms.Resize((args.crop_size, args.crop_size))\n",
        "\n",
        "        self.imglist = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for filespath in files:\n",
        "                self.imglist.append(os.path.join(root, filespath))        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = torchvision.io.read_image(self.imglist[index])\n",
        "\n",
        "        if self.is_train:\n",
        "            img = self.cropper(img)\n",
        "            img = self.flipper(img)\n",
        "            img = F2.rotate(img, 90.0 * random.randint(0, 4))\n",
        "        else:\n",
        "            img = self.resizer(img)\n",
        "\n",
        "        noise = torch.normal(torch.full(img.shape, args.mu), torch.full(img.shape, args.sigma))\n",
        "        noisy_img = img + noise\n",
        "        noisy_img = torch.where(noisy_img < 0.0, 0.0, noisy_img)\n",
        "        noisy_img = torch.where(noisy_img > 256.0, 256.0, noisy_img)\n",
        "        \n",
        "        img = (img - 128) / 128\n",
        "        noisy_img = (noisy_img - 128) / 128\n",
        "\n",
        "        return noisy_img, img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "train_dataset = DatasetClass(is_train=True)\n",
        "test_dataset = DatasetClass(is_train=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWfSWriHmhVN"
      },
      "outputs": [],
      "source": [
        "# Setup tensorboard.\n",
        "if args.tensorboard:\n",
        "    from torch.utils.tensorboard import SummaryWriter \n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir \"/gdrive/My Drive/{str(result_dir).replace('/gdrive/My Drive/', '')}\"\n",
        "else:\n",
        "    writer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tBjxWg8mttr"
      },
      "outputs": [],
      "source": [
        "def train_net(net, optimizer, scheduler, writer):\n",
        "    global_step = 0\n",
        "    best_psnr = 0\n",
        "\n",
        "    for epoch in range(args.epoch):\n",
        "        # Here starts the train loop.\n",
        "        net.train()\n",
        "        for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            #  Send `x` and `y` to either cpu or gpu using `device` variable. \n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            # Feed `x` into the network, get an output, and keep it in a variable called `logit`. \n",
        "            y_pred = net(x)\n",
        "\n",
        "            # Compute loss using `y_pred` and `y`, and keep it in a variable called `loss`.\n",
        "            loss = nn.MSELoss()(y_pred, y)\n",
        "\n",
        "            # flush out the previously computed gradient.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # backward the computed loss. \n",
        "            loss.backward()\n",
        "\n",
        "            # update the network weights. \n",
        "            optimizer.step()\n",
        "\n",
        "            if global_step % args.log_iter == 0 and writer is not None:\n",
        "                # Log loss and accuracy values using `writer`. Use `global_step` as a timestamp for the log. \n",
        "                writer.add_scalar('train_loss', loss, global_step)\n",
        "                #writer.add_scalar('train_psnr', psnr, global_step)\n",
        "\n",
        "            if global_step % args.ckpt_iter == 0: \n",
        "                # Save network weights in the directory specified by `ckpt_dir` directory. \n",
        "                torch.save(net.state_dict(), f'{ckpt_dir}/{global_step}.pt')\n",
        "\n",
        "        # Here starts the test loop.\n",
        "        net.eval() \n",
        "        with torch.no_grad():\n",
        "            test_psnr = 0.\n",
        "            test_loss = 0.\n",
        "            test_num_data = 0.\n",
        "            for batch_idx, (x, y) in enumerate(test_dataloader):\n",
        "                # Send `x` and `y` to either cpu or gpu using `device` variable..\n",
        "                x = x.to(device=device)\n",
        "                y = y.to(device=device)\n",
        "\n",
        "                y_pred = net(x)\n",
        "                loss = nn.MSELoss()(y_pred, y)\n",
        "\n",
        "                test_loss += loss.item() * x.shape[0]\n",
        "\n",
        "                for a, b in zip(y_pred, y):                    \n",
        "                    aa = torch.mul(torch.add(a, 1), 128)\n",
        "                    bb = torch.mul(torch.add(b, 1), 128)\n",
        "                    test_psnr += 20 * math.log10(255) - 10 * math.log10(F.mse_loss(aa, bb).item())\n",
        "\n",
        "                test_num_data += x.shape[0]\n",
        "\n",
        "            test_loss /= test_num_data\n",
        "            test_psnr /= test_num_data\n",
        "\n",
        "            if writer is not None: \n",
        "                # Log loss and accuracy values using `writer`. Use `global_step` as a timestamp for the log. \n",
        "                writer.add_scalar('test_loss', test_loss, global_step)\n",
        "                writer.add_scalar('test_psnr', test_psnr, global_step)\n",
        "\n",
        "                # Just for checking progress\n",
        "                print(f'Test result of epoch {epoch}/{args.epoch} || loss : {test_loss:.3f} psnr : {test_psnr:.3f} ')\n",
        "\n",
        "                writer.flush()\n",
        "\n",
        "            # Whenever `test_accuracy` is greater than `best_accuracy`, save network weights with the filename 'best.pt' in the directory specified by `ckpt_dir`.\n",
        "            if test_psnr > best_psnr:\n",
        "                best_psnr = test_psnr\n",
        "                torch.save(net.state_dict(), f'{ckpt_dir}/best.pt')\n",
        "    \n",
        "        scheduler.step()\n",
        "    return best_psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRCXvvVr_Kof"
      },
      "outputs": [],
      "source": [
        "# Function for weight initialization.\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.constant_(m.weight, 1)\n",
        "        torch.nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBEI6oSP_LlM",
        "outputId": "5d9df91a-4784-4145-be31-570cc9bb9f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logs and ckpts will be saved in : /gdrive/My Drive/CS492I/project/results/trial_10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGN(\n",
              "  (bottom): SubNetwork(\n",
              "    (act): ReLU()\n",
              "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (conv2): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (conv_last): ModuleList(\n",
              "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (3): ReLU()\n",
              "      (4): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (middle): ModuleList(\n",
              "    (0): SubNetwork(\n",
              "      (act): ReLU()\n",
              "      (conv1): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (res_block): ModuleList(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (conv_last): ModuleList(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): SubNetwork(\n",
              "      (act): ReLU()\n",
              "      (conv1): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (res_block): ModuleList(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (conv_last): ModuleList(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (top): SubNetwork(\n",
              "    (act): ReLU()\n",
              "    (conv1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (res_block): ModuleList(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (3): ReLU()\n",
              "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (conv_last): ModuleList(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "# Create directory name.\n",
        "num_trial=0\n",
        "parent_dir = result_dir / f'trial_{num_trial}'\n",
        "while parent_dir.is_dir():\n",
        "    num_trial = int(parent_dir.name.replace('trial_',''))\n",
        "    parent_dir = result_dir / f'trial_{num_trial+1}'\n",
        "print(f'Logs and ckpts will be saved in : {parent_dir}')\n",
        "\n",
        "# Define network\n",
        "net = SGN(args).to(device)\n",
        "net.apply(weight_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gslmcvuVDqiW"
      },
      "outputs": [],
      "source": [
        "final_psnr = 0\n",
        "\n",
        "# Start training\n",
        "try:\n",
        "    optimizer = optim.Adam(net.parameters(), lr=args.lr, betas=args.betas, weight_decay=args.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000], gamma=0.1)\n",
        "    \n",
        "    # Create directories for logs and ckechpoints.\n",
        "    ckpt_dir = parent_dir / args.ckpt_dir\n",
        "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir = parent_dir / args.log_dir\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create tensorboard writer,\n",
        "    if args.tensorboard: \n",
        "        writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # Call the train & test function.\n",
        "    t1 = time.time()\n",
        "    final_psnr = train_net(net, optimizer, scheduler, writer)\n",
        "    t = time.time() - t1\n",
        "    print(f'Best psnr: {final_psnr:.3f} took {t:.3f} secs')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Print final best accuracies of the model.\n",
        "print(f'Best psnr = {final_psnr:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6nAFAA4FKbl"
      },
      "outputs": [],
      "source": [
        "# Aggregating experimental results\n",
        "\n",
        "ckpt_dir = parent_dir / args.ckpt_dir\n",
        "\n",
        "# load weights from best checkpoints.\n",
        "ckpt_path = f'{ckpt_dir}/best.pt'\n",
        "try:\n",
        "    net.load_state_dict(torch.load(ckpt_path))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Measure test performance.\n",
        "net.eval() \n",
        "with torch.no_grad():\n",
        "    test_psnr = 0.\n",
        "    test_num_data = 0.\n",
        "    for batch_idx, (x, y) in enumerate(test_dataloader):\n",
        "        # Send `x` and `y` to either cpu or gpu using `device` variable..\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(device=device)\n",
        "\n",
        "        y_pred = net(x)\n",
        "        loss = nn.MSELoss()(y_pred, y)\n",
        "\n",
        "        for a, b in zip(y_pred, y):                    \n",
        "            aa = torch.mul(torch.add(a, 1), 128)\n",
        "            bb = torch.mul(torch.add(b, 1), 128)\n",
        "            test_psnr += 20 * math.log10(255) - 10 * math.log10(F.mse_loss(aa, bb).item())\n",
        "\n",
        "        test_num_data += x.shape[0]\n",
        "\n",
        "test_psnr /= test_num_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y952pVAjF7w4"
      },
      "outputs": [],
      "source": [
        "# Printing final results.\n",
        "print(test_psnr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}